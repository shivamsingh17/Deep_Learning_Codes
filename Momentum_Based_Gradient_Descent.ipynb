{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Momentum Based Gradient Descent.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/shivamsingh17/Deep_Learning_Codes/blob/master/Momentum_Based_Gradient_Descent.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "adz16tIGp4qq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1768
        },
        "outputId": "59b36b93-f237-4c55-f018-33325d4d1601"
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "def f(w,b,x):\n",
        "    return 1.0/(1.0+np.exp(-(w*x+b)))\n",
        "def grad_b(w,b,x,y):\n",
        "    fx=f(w,b,x)\n",
        "    return (fx-y)*fx*(1-fx)\n",
        "def grad_w(w, b, x, y):\n",
        "    fx = f(w, b, x)\n",
        "    return (fx - y) * fx * (1 - fx) * x\n",
        "  \n",
        "def error(w,b):# calculate loss/error\n",
        "    err=0.0\n",
        "    for x,y in zip(X,Y):\n",
        "        fx = f(w,b,x)\n",
        "        err += 0.5*(fx-y)**2\n",
        "    return err\n",
        "def do_momentum_gradient_descent(X,Y,init_w,init_b,max_epochs):\n",
        "    w, b, eta = init_w, init_b, 1.0\n",
        "    prev_v_w, prev_v_b, gamma = 0, 0, 0.9\n",
        "    for i in range(max_epochs):\n",
        "        dw, db = 0,0\n",
        "        for x,y in zip(X,Y):\n",
        "            dw += grad_w(w,b,x,y)\n",
        "            db += grad_b(w,b,x,y)\n",
        "            \n",
        "        v_w = gamma * prev_v_w + eta* dw\n",
        "        v_b = gamma * prev_v_b + eta* db\n",
        "        w = w - v_w\n",
        "        b = b - v_b\n",
        "        prev_v_w = v_w\n",
        "        prev_v_b = v_b\n",
        "        print(\"Epoch{}: Loss={}\".format(i,error(w,b)))\n",
        "    \n",
        "    return w,b\n",
        "  \n",
        "if __name__==\"__main__\":\n",
        "    filename='A2_Q4_data.csv'\n",
        "    df=pd.read_csv(filename)\n",
        "    X=df['X']\n",
        "    Y=df['Y']\n",
        "    initial_w=1\n",
        "    initial_b=1\n",
        "    max_epochs=100\n",
        "    w,b=do_momentum_gradient_descent(X,Y,initial_w,initial_b,max_epochs)\n",
        "    error=error(w,b)\n",
        "    print(\"Error={}\".format(error))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch0: Loss=0.025154357598516662\n",
            "Epoch1: Loss=0.005742165827785046\n",
            "Epoch2: Loss=0.004429526156669953\n",
            "Epoch3: Loss=0.009321023932759602\n",
            "Epoch4: Loss=0.014098841123542628\n",
            "Epoch5: Loss=0.01675413689732964\n",
            "Epoch6: Loss=0.017207092096132772\n",
            "Epoch7: Loss=0.01607726583922297\n",
            "Epoch8: Loss=0.01412132787692757\n",
            "Epoch9: Loss=0.011963769844975991\n",
            "Epoch10: Loss=0.00999682457785147\n",
            "Epoch11: Loss=0.008402394664301345\n",
            "Epoch12: Loss=0.007238933580044097\n",
            "Epoch13: Loss=0.006527888426200371\n",
            "Epoch14: Loss=0.006293289280664757\n",
            "Epoch15: Loss=0.006541069944409284\n",
            "Epoch16: Loss=0.00719989163716305\n",
            "Epoch17: Loss=0.008074983067474006\n",
            "Epoch18: Loss=0.008869413714993016\n",
            "Epoch19: Loss=0.009283902402962152\n",
            "Epoch20: Loss=0.00914142885875921\n",
            "Epoch21: Loss=0.008456443630281541\n",
            "Epoch22: Loss=0.007407689302577009\n",
            "Epoch23: Loss=0.006241553492287943\n",
            "Epoch24: Loss=0.00517083854711856\n",
            "Epoch25: Loss=0.004318721038860421\n",
            "Epoch26: Loss=0.0037152200497661595\n",
            "Epoch27: Loss=0.0033236106159970713\n",
            "Epoch28: Loss=0.0030719269040946286\n",
            "Epoch29: Loss=0.0028775979461954644\n",
            "Epoch30: Loss=0.0026646879090394793\n",
            "Epoch31: Loss=0.0023770276096315786\n",
            "Epoch32: Loss=0.0019890023229527745\n",
            "Epoch33: Loss=0.0015128108139995365\n",
            "Epoch34: Loss=0.0009989309189250293\n",
            "Epoch35: Loss=0.0005261832848308599\n",
            "Epoch36: Loss=0.00017975476755193552\n",
            "Epoch37: Loss=2.0472258347822457e-05\n",
            "Epoch38: Loss=5.59008546741235e-05\n",
            "Epoch39: Loss=0.00022937679036918977\n",
            "Epoch40: Loss=0.0004395607061511745\n",
            "Epoch41: Loss=0.0005865118991731577\n",
            "Epoch42: Loss=0.0006192704816200698\n",
            "Epoch43: Loss=0.0005541206594660046\n",
            "Epoch44: Loss=0.00045258270926237635\n",
            "Epoch45: Loss=0.0003778286561772152\n",
            "Epoch46: Loss=0.0003602179586449978\n",
            "Epoch47: Loss=0.00038956000482317203\n",
            "Epoch48: Loss=0.00043050350042862757\n",
            "Epoch49: Loss=0.0004460158942518182\n",
            "Epoch50: Loss=0.00041534176434419927\n",
            "Epoch51: Loss=0.0003402967668541367\n",
            "Epoch52: Loss=0.0002406801393559453\n",
            "Epoch53: Loss=0.00014342828508969433\n",
            "Epoch54: Loss=7.1066733611801e-05\n",
            "Epoch55: Loss=3.397255553590131e-05\n",
            "Epoch56: Loss=2.8740895516865916e-05\n",
            "Epoch57: Loss=4.228014367427837e-05\n",
            "Epoch58: Loss=5.90057748893924e-05\n",
            "Epoch59: Loss=6.755935240486794e-05\n",
            "Epoch60: Loss=6.425730003773786e-05\n",
            "Epoch61: Loss=5.2470882470681e-05\n",
            "Epoch62: Loss=3.916499259313024e-05\n",
            "Epoch63: Loss=3.0812243205516804e-05\n",
            "Epoch64: Loss=3.058544355529353e-05\n",
            "Epoch65: Loss=3.764094758553882e-05\n",
            "Epoch66: Loss=4.8205784946995305e-05\n",
            "Epoch67: Loss=5.7564780161628855e-05\n",
            "Epoch68: Loss=6.198074696956006e-05\n",
            "Epoch69: Loss=5.9879240092472366e-05\n",
            "Epoch70: Loss=5.2050041062938915e-05\n",
            "Epoch71: Loss=4.099274850957528e-05\n",
            "Epoch72: Loss=2.9781202050633855e-05\n",
            "Epoch73: Loss=2.091345597734717e-05\n",
            "Epoch74: Loss=1.55528987146735e-05\n",
            "Epoch75: Loss=1.3380485270893663e-05\n",
            "Epoch76: Loss=1.3029529884593155e-05\n",
            "Epoch77: Loss=1.2852924074958976e-05\n",
            "Epoch78: Loss=1.1666651292192366e-05\n",
            "Epoch79: Loss=9.166220580672043e-06\n",
            "Epoch80: Loss=5.892508842089684e-06\n",
            "Epoch81: Loss=2.8367127572518393e-06\n",
            "Epoch82: Loss=9.168080147277704e-07\n",
            "Epoch83: Loss=5.734090074709291e-07\n",
            "Epoch84: Loss=1.6358763821039538e-06\n",
            "Epoch85: Loss=3.46575554414828e-06\n",
            "Epoch86: Loss=5.267325091165465e-06\n",
            "Epoch87: Loss=6.408261161513527e-06\n",
            "Epoch88: Loss=6.6203391585721385e-06\n",
            "Epoch89: Loss=6.0232203665741585e-06\n",
            "Epoch90: Loss=4.995083965988591e-06\n",
            "Epoch91: Loss=3.96965924107106e-06\n",
            "Epoch92: Loss=3.2536165336732085e-06\n",
            "Epoch93: Loss=2.9331475476565413e-06\n",
            "Epoch94: Loss=2.8903009377309975e-06\n",
            "Epoch95: Loss=2.9011836976121794e-06\n",
            "Epoch96: Loss=2.7593568504183476e-06\n",
            "Epoch97: Loss=2.3676125733133274e-06\n",
            "Epoch98: Loss=1.7652345526403226e-06\n",
            "Epoch99: Loss=1.0913943873622581e-06\n",
            "Error=1.0913943873622581e-06\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XdFEN8Gbp4sN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cA2Ux54Ip4sW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}